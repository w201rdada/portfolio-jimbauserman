# Online Ad Text Shuffler (OATS) {#ad-shuffler}

#### Abstract {-}

(ref:abs1)

#### Keywords {-}

search engine marketing, online advertising, natural language processing, ad testing

## Ad copy is a major driver of clickthrough rates (CTR), but is hard to evaluate

The specific text displayed in a search advertisement on Google or Bing can be crucial to driving traffic to an advertiser's site. However, the performance of specific ads (evaluated in terms of CTR) is driven by a wide variety of factors beyond the actual ad text, including the users that are seeing the ad, the ad's compatibility with the user's search query, and the relative strength of competing ads or organic content on the search engine result page (SERP). Moreover, since ad copy is written in natural language, there are a huge variety of options to choose from and no well-defined cost function to optimize. As a result, it is extremely difficult to identify which words and phrases are the best at getting users to click on an ad.

Higher CTRs are not only beneficial for their own sake, but also because they provide better quality scores. Quality score is a metric used by search engines to weight the relative strength of ads that are bidding for a specific keyword, and allows bidders with relatively high quality scores to show their ads more prominently even at lower bids. Thus, suboptimal ads with low CTRs can cause an advertiser to pay more than they otherwise would for the same ad placement. In addition, since the history of a specific ad-keyword combination is an important factor in the quality score, even a high-quality ad that is added to a new keyword will suffer a temporary period where the advertiser is paying higher costs while the search engine observes enough user behavior to establish the quality score of the ad for that keyword [@wikipedia_quality_2017]. These costs are sometimes referred to as "burn-in costs" and they are a major hurdle to traditional A/B testing of ads. ^[Note that these costs are distinct from the cost of bidding higher with the express purpose of getting more impressions or ranking higher on a SERP. While the overall return on ad spend (ROAS) depends on both CTR and bids, ad effectiveness and bids can be optimized separately, and bid optimization is beyond the scope of this project.] After the burn-in period has passed, higher quality ads will provide large, long-run cost savings for an advertiser, so getting around this hurdle is important.

## The effectiveness of ads can be assessed through experiments

In order to disentangle the effectiveness of specific ad copy from other confounding factors, Online Ad Text Shuffler (OATS) would categorize an advertiser's existing ad copy and use these categories to conduct controlled experiments. First, OATS would use natural language processing (NLP) to group ads into clusters based on their semantic similarity. For example, a shoe company might be running ads like "Buy The Hottest Styles", "Find The Perfect Shoe For You", or "Check Out Our Sales!", with many small variations on these templates (e.g. "Find The Perfect [Heels/Flats/Sneakers] For You"). While these are examples of title text, ads are composed of multiple discrete text fields, each of which would be separately clustered. OATS would then form a map of the ad space, noting which clusters are most similar (possibly forming a hierarchy of classifications), and the relationships between different title texts and sub-parts that support them. OATS would also evaluate the semantic relationship between ads and the keywords on which they appear. This would distinguish between "all-purpose" ads that work with any keyword and targeted ads that only work on particular keywords. (Some ads can even contain dynamic text that substitutes the keyword into the ad copy when the SERP loads, which would be an extreme example of a targeted ad.)

OATS would then use existing performance data in combination with its classifications to form hypotheses about which types of ads perform best. While these hypotheses would be imperfect, it is already a best practice to serve multiple ads for each keyword [@irvine_these_2018], so there would likely be enough variation in a typical advertiser's portfolio to form useful priors about the relative effectiveness of some types of ads. Using these priors, OATS would determine a minimal sample of ads to shift between keywords in order to confirm or deny its hypotheses (to an appropriate level of statistical significance). Obtaining the most information from the least amount of shuffling is crucial, as it helps to mitigate burn-in costs. For instance, OATS might have a hypotheses that ads in the "Buy The Hottest Styles" cluster are particularly strong, and would shuffle a small sample of them to lower performing keywords to see if their success continued there. Similarly, OATS would avoid shuffling targeted ads away from keywords that are appropriate for them, but might switch two targeted ads between two relevant keywords. Sub-parts of the ads could also be mixed and matched at this time to further refine judgments.

After the burn-in period for the treatment ads had passed, OATS would record their CTRs and update its hypotheses accordingly. This process could be repeated any number of times, and could even be a continuous process with new experiments launched every day or week. OATS would provide reports on its estimates of the best ads, along with details of its confidence in these assessments. The advertiser could then weigh the tradeoffs between increased precision and continued burn-in costs. Once the advertiser was satisfied that the best ads had indeed been identified accurately enough, OATS could be switched from "experiment" to "optimize" mode, and begin slowly restructuring ads to propagate the best performing ads throughout the advertiser's account.

As an extension of this process, OATS could use more complex NLP to assign additional features to ads such as urgency, personalization, or use of the imperative. (If OATS formed a hierarchical map of the ad clusters, such features might form some of the top-level categories.) This would abstract from the specific ad copy to determine which generic features are most predictive of high CTRs. Advertiser's could then generate new, optimized ad copy based on these features, rather than just identifying the best practices among existing ads.

## Identifying the best ad copy will improve CTR

Even small improvements in CTR can have a large impact on an advertiser's business. Better ads with higher CTRs contribute directly to more traffic arriving on an advertiser's site as well as better quality scores, allowing the advertiser to purchase that traffic for cheaper. This discount amounts to as much as 50% for the highest quality scores [@wordstream_quality_nodate]. For a large-scale search advertising operation, such savings could amount to several thousand dollars *per day*. Moreover, this discount would allow the advertiser to increase their bids while remaining profitable, further increasing their traffic. In addition, better quality ads create intangible benefits for the advertiser's brand as more users associate the brand name with more pleasing and (hopefully) more useful content, even if they don't click on the ads. In an ideal scenario, this "halo effect" for the brand could even drive up CTRs as the advertiser is seen as more helpful and trustworthy, building on the virtuous cycle. By mitigating the costs of finding this optimal state (both financially and in terms of manual labor), OATS could provide a huge return on investment for an online advertiser.
